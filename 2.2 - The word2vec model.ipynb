{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113850400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "y_hat_t = np.arange(0.001, 1.0, 0.005)\n",
    "loss = np.log(y_hat_t)\n",
    "plt.plot(y_hat_t, loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Word2vec is a model that maps words from a vocabulary to vectors that have typically 100 to 300 dimensions.\n",
    "\n",
    "Model training takes as input a large document collection and assigns each unique word a corresponding vector.\n",
    "\n",
    "The model training is **unsupervised**.\n",
    "\n",
    "Words that appear in similar contexts in the document collection have vectors that are located in close distance to each other.\n",
    "\n",
    "It can be shown that word vectors actually encode word meanings and relations between them.\n",
    "\n",
    "The interesting idea of the word2vec algorithm is that it generates the word vectors as a by-product of solving a **classification problem**.\n",
    "\n",
    "A word2vec model takes fix-sized subsequences of words from the document collection and predicts the center word. \n",
    "\n",
    "The model internally represents every word as a word vector and the training process modifies the vectors so that they encode word semantic. \n",
    "\n",
    "\n",
    "## Optimization objective\n",
    "\n",
    "We need a **vocabulary** that maps every word to a word ID $w_i$.\n",
    "\n",
    "The model is trained on a sequence of training word IDs $\\{w_1,w_2,...,w_T\\}$ from the collection of documents.\n",
    "\n",
    "Given a **word context** $[w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k}]$ of size $2k$, the model predicts the center word $w_t$. \n",
    "\n",
    "This is a **classification problem** where the examples are the word contexts and the classes are the words in the vocabulary.\n",
    "\n",
    "More specifically, given a context, the model outputs a conditional probability distribution over all words $w_i$ in the vocabulary to be the center word $w_t$:\n",
    "\n",
    "$$P(w_i=w_t \\mid w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k})$$\n",
    "\n",
    "\n",
    "The optimization objective is to **maximize** the average probability over all examples:\n",
    "\n",
    "$$\n",
    "\\frac{1}{T} \\sum^{T-k}_{t=k} P(w_t \\mid w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k})\n",
    "$$\n",
    "\n",
    "Note that we are only interested in the predicted probabilities of the true center word (this is a hint for cross entropy!).\n",
    "\n",
    "Maximizing a probability is the same as maximizing the log of the probability. \n",
    "\n",
    "Therefore we can change the expression to maximize the average log probability instead of the average probability:\n",
    "\n",
    "$$\n",
    "\\frac{1}{T} \\sum^{T-k}_{t=k} log \\ P(w_t \\mid w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k})\n",
    "$$\n",
    "\n",
    "Maximizing an expression is exactly the same as minimizing the negative of the expression.\n",
    "\n",
    "So if we just put a minus sign in front of the expression and minimize it we can use the cross-entropy loss function with gradient descent to train the model.\n",
    "\n",
    "The **final optimization objective** is to minimize the following expression:\n",
    "\n",
    "$$\n",
    "- \\frac{1}{T} \\sum^{T-k}_{t=k} log \\ P(w_t \\mid w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k})\n",
    "$$\n",
    "\n",
    "\n",
    "## How does the model work\n",
    "\n",
    "The model **input** is a vector $[w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k}]$ of size $2k$ that represents the context for the target value $w_t$.\n",
    "\n",
    "Every word from a vocabulary of size $m$ is mapped to a unique vector, represented by a column in an **embedding matrix** $W$.\n",
    "\n",
    "$W$ is initialized with small random values.\n",
    "\n",
    "Lets define a function $h(w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k}; W)$ that takes a context as input and is parametrized by $W$. \n",
    "\n",
    "$h$ extracts the word vectors from $W$ and aggregates them by one of the following operations:\n",
    "\n",
    " * concatenate\n",
    " * average\n",
    " * sum\n",
    "\n",
    "<img src=\"images/word2vec.png\" height=\"250\" width=\"400\"/> \n",
    "\n",
    "Than we do the following calculation:\n",
    "\n",
    "$$\n",
    "z = U \\cdot h(w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k}; W) + b \n",
    "$$\n",
    "\n",
    "$\\cdot$ is the dot product\n",
    "\n",
    "$U$ is a weight matrix and $b$ is a bias vector.\n",
    "\n",
    "$ z = [z_1,...,z_m]$ is a vector that has as many dimensions are we have words in the vocabulary. \n",
    "\n",
    "Each $z_i$ is the **unnormalized probability** that $w_i$ is the center word given the context.\n",
    "\n",
    "We use the softmax function to normalize the probabilities:\n",
    "\n",
    "$$\n",
    "P(w_i \\mid w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k}) = \\frac{e^{z_i}}{\\displaystyle\\sum_{j=1}^T {e^{z_j}}}\n",
    "$$\n",
    "\n",
    "Finally we use the cross-entropy loss as optimization objective:\n",
    "\n",
    "$$\n",
    " L = - \\frac{1}{T} \\sum^{T-k}_{t=k} log \\ P(w_t \\mid w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k})\n",
    "$$\n",
    "\n",
    "$W$, $U$ and $b$ are the trainable weights of the model. \n",
    "\n",
    "Note that $W$ is a trainable parameter as well, its values are modified by the optimizer.\n",
    "\n",
    "After training has converged the columns in $W$ are the vector representations of the words in the vocabulary.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The implementation of the model is quite simple.\n",
    "\n",
    "The function $h$ can be implemented by two components:\n",
    "\n",
    " 1. An [Embedding layer](https://keras.io/layers/embeddings/) performs the lookup of the word vectors in $W$\n",
    " 2. The aggregation of the word vectors is performed by a [Concatenate](https://keras.io/layers/merge/#concatenate), [Average](https://keras.io/layers/merge/#average) or [Add](https://keras.io/layers/merge/#add) layer.\n",
    " \n",
    "The calculation $z = U \\cdot h + b$ is performed by a [Dense](https://keras.io/layers/core/#dense) layer. \n",
    "\n",
    "The Dense layer will be configured with a softmax activation.\n",
    "\n",
    "The loss will be calculated by a cross-entropy loss function.\n",
    "\n",
    "The model will be optimized by Stochastic Gradient Descent.\n",
    "\n",
    "After training has converged a snapshot of the model will be saved.\n",
    "\n",
    "The final model will usually not be used for prediction because we are only interested in the word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result\n",
    "\n",
    "Despite the fact that the word vectors are initialized randomly, they can eventually capture semantics as an indirect result of the prediction task.\n",
    "\n",
    "After the training converges, words with similar meaning are mapped to a similar position in the vector space. \n",
    "\n",
    "For example: \n",
    " * `powerful` and `strong` are close to each other\n",
    " * whereas `powerful` and `Paris` are more distant.\n",
    "\n",
    "The difference between word vectors also carry meaning. \n",
    "\n",
    "For example, the word vectors can be used to answer analogy questions using simple vector algebra: \n",
    "\n",
    "\"king\" - \"man\" + \"woman\" = \"queen\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
