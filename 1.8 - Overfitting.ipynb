{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We track model accuracy during training and evaluation but evaluation accuracy is the primary measure for model quality. We want the model to generalize well, this means to perform well on data it has not seen during training.\n",
    "\n",
    "**Overfitting** happens when a model becomes to sensitive to noise that is specific for the training data and does not generalize well to unseen data. \n",
    "\n",
    "**Underfitting** occurs when a statistical model cannot adequately capture the underlying structure of the data. Such a model will tend to have poor predictive performance.\n",
    "\n",
    "Here is a cartoon example of overfitting:\n",
    "\n",
    "<img src=\"images/overfitting.png\" height=\"200\" width=\"300\"/>\n",
    "\n",
    "The green line represents an overfitted model. While it best follows the training data, it is too dependent on that data and it is likely to have a higher error rate on new unseen data, compared to the black line.\n",
    "\n",
    "The gap between the training and validation accuracy indicates the amount of overfitting.\n",
    "\n",
    "<img src=\"images/accuracies.jpg\" height=\"200\" width=\"300\"/>\n",
    "\n",
    "**Overfitting**\n",
    "\n",
    "The blue validation error curve shows very small validation accuracy compared to the training accuracy. It's possible for the validation accuracy to even start to go down after some point. \n",
    "\n",
    "What you can do about it:\n",
    " * increase regularization:\n",
    "     * add dropout layers or increase dropout rate\n",
    "     * stronger L1/L2 weight penalty\n",
    " * collect more data and increase the size of the train dataset\n",
    " * reduce the number of parameters\n",
    "\n",
    "In general **regularization** is a set to methods that make it harder for the model to learn.\n",
    "\n",
    "**Underfitting**\n",
    "\n",
    "The other possible case is when the validation accuracy tracks the training accuracy fairly well. This case indicates that your model capacity is not high enough and you are wasting learning opportunities. \n",
    "\n",
    "Make the model larger by: \n",
    " * increasing the number of parameters in existing layers\n",
    " * add more layers\n",
    "\n",
    "In practice you can balance over- and underfitting through experiments. You actually want to see overfitting but you want to see at the best validation accuracy that you can achive. Stop training early when validation accuracy starts to drop and use the model checkpoint with the best performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
