{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We track model accuracy during training and evaluation but evaluation accuracy is the primary measure for model quality. \n",
    "\n",
    "We want the model to generalize well, this means to perform well on data it has not seen during training.\n",
    "\n",
    "**Overfitting** happens when a model becomes to sensitive to noise that is specific for the training data and does not generalize well to unseen data. \n",
    "\n",
    "**Underfitting** occurs when a statistical model cannot adequately capture the underlying structure of the data. Such a model will tend to have poor predictive performance.\n",
    "\n",
    "Here is a cartoon example of overfitting:\n",
    "\n",
    "<img src=\"images/overfitting.png\" height=\"200\" width=\"300\"/>\n",
    "\n",
    "This is a binary classification problem and the task is to classify points as either blue or red.\n",
    "\n",
    "The black and green lines are decision boundaries for two different models on the train dataset.\n",
    "\n",
    "The model that represents the green line is overfitting. It does a very good job in separating the classes but is too dependent on that data and is likely to have a higher error rate on new unseen data.\n",
    "\n",
    "The model that represents the black line has a lower train accuracy but is likely to generalize better.\n",
    "\n",
    "We can plot accuracy over time and the gap between the training and validation accuracy is a good indication for the amount of overfitting.\n",
    "\n",
    "\n",
    "<img src=\"images/accuracies.jpg\" height=\"200\" width=\"300\"/>\n",
    "\n",
    "The large gap between train accuracy and the blue validation accuracy is an indication for **overfitting**.\n",
    "\n",
    "It's possible for the validation accuracy to even start to go down after some point. \n",
    "\n",
    "Possible solutions:\n",
    "\n",
    " * reduce the number of parameters in the model\n",
    " * collect more data and increase the size of the train dataset\n",
    " * increase regularization:\n",
    "     * add dropout layers or increase dropout rate\n",
    "     * stronger L1/L2 weight penalty\n",
    "\n",
    "\n",
    "In general **regularization** is a set to methods that make it harder for the model to learn.\n",
    "\n",
    "The other case is when the validation accuracy tracks the training accuracy fairly well. This case indicates that your model capacity is not high enough and you are wasting learning opportunities. \n",
    "\n",
    "Make the model larger by: \n",
    " * increasing the number of parameters in existing layers\n",
    " * add more layers\n",
    "\n",
    "In practice you can balance over- and underfitting through experiments. You actually want to see overfitting but you want to see at the best validation accuracy that you can achive. Stop training early when validation accuracy starts to drop and use the model checkpoint with the best performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
