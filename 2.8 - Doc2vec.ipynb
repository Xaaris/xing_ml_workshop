{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[Doc2vec](https://arxiv.org/abs/1405.4053) takes the idea of word2vec one step further and generates embeddings for variable-length pieces of texts, such as sentences, paragraphs, and documents. \n",
    "\n",
    "The result are document vectors that capture the semantic of the associated texts. \n",
    "\n",
    "In practice this means that similar documents have similar vector representations.\n",
    "\n",
    "This means you could take a particular document and lookup the top-5 most similar documents.\n",
    "\n",
    "One practical application would be to create a representation of a user's interests. Create an interest vector by averaging the documents vectors of all articles the user has clicked, read, liked or shard within the last 4 weeks. For the interest vector lookup the top-k most similar articles and you have candidates for article recommendations.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Every document is mapped to a unique vector, represented by a column in matrix $D$ and every word is also mapped to a unique vector, represented by a column in matrix $W$.\n",
    "\n",
    "The model input is a vector $[w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k}, docId]$ that represents a context together with the document ID the context originates from.\n",
    "\n",
    "The only change in the doc2vec model compared to the word2vec framework is that $h$ is now constructed from $W$ and $D$:\n",
    "\n",
    "$$h(w_{t-k},...,w_{t-1}, w_{t+1},...,w_{t+k}, docId;W,D)$$\n",
    "\n",
    "$h$ extracts the word vectors from $W$, extracts the document vector from $D$ and aggregates them with one of:\n",
    "\n",
    " * concatenate\n",
    " * average\n",
    " * sum\n",
    "\n",
    "<img src=\"images/doc2vec.png\" height=\"250\" width=\"400\"/> \n",
    "\n",
    "The document vector is shared across all contexts generated from the same document but not across documents. \n",
    "\n",
    "The word vectors are shared across documents, i.e. the vector for “powerful” is the same for all paragraphs.\n",
    "\n",
    "With the exception of introducing $D$ and the described changes in $h$ everything works exactly as in the word2vec framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
