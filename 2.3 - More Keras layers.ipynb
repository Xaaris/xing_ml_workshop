{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer\n",
    "\n",
    "An [embedding layer](https://keras.io/layers/embeddings/) turns integers into dense vectors of fixed size. \n",
    "\n",
    "In our case it will translate word IDs from the vocabulary into word vectors.\n",
    "\n",
    "Usually the word vectors are initialized with small random numbers and learned during training. \n",
    "\n",
    "It is also possible to initialize an embedding layer with pre-trained word vectors. \n",
    "\n",
    "A common scenario is to pre-train word vectors on a large corpus like Wikipedia and than re-use the word vectors in other models. The idea is to inject general language understanding into the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word input:\n",
      "[[0 1 1 1 2]]\n",
      "\n",
      "Word vectors:\n",
      "[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "  [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "  [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "  [20. 20. 20. 20. 20. 20. 20. 20. 20. 20.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "# Size of the vocabulary. Indexing must\n",
    "# starts with 0 and be consequtive.\n",
    "vocab_size = 3\n",
    "\n",
    "# Size of word vectors\n",
    "embedding_dims = 10\n",
    "\n",
    "# Pre-define word vectors:\n",
    "# word 0 => [0, 0,...]\n",
    "# word 1 => [10, 10,...]\n",
    "# word 2 => [20, 20,...]\n",
    "word_vectors = []\n",
    "for i in range(vocab_size):\n",
    "    wvec = np.empty((embedding_dims,))\n",
    "    wvec.fill(i*10)\n",
    "    word_vectors.append(wvec)\n",
    "weights = np.vstack(word_vectors)\n",
    "\n",
    "# Size of word input\n",
    "input_size = 5\n",
    "\n",
    "inputs = Input(shape=(input_size,), dtype='int32') \n",
    "outputs = Embedding(vocab_size, embedding_dims, weights=[weights])(inputs)\n",
    "model = Model([inputs], [outputs])\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "word_ids = np.array([[0,1,1,1,2]])\n",
    "word_vectors = model.predict(word_ids)\n",
    "\n",
    "print('Word input:')\n",
    "print(word_ids)\n",
    "print('\\nWord vectors:')\n",
    "print(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda layer\n",
    "\n",
    "A [lambda layer](https://keras.io/layers/core/#lambda) is a simple way to add custom functionality to a model. \n",
    "\n",
    "It is best used for stateless functions. For stateful functions it is better to implement a separate layer.\n",
    "\n",
    "In our case we'll use a lambda layer to slice the output from an embedding layer into individual word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:\n",
      "[[1. 1. 1. 1.]]\n",
      "\n",
      "First column:\n",
      "[[1. 2. 3. 4.]]\n",
      "\n",
      "Multiplied by 2:\n",
      "[[[2. 2. 2. 2.]\n",
      "  [4. 4. 4. 4.]\n",
      "  [6. 6. 6. 6.]\n",
      "  [8. 8. 8. 8.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "# define the input shape\n",
    "inputs = Input(shape=(4,4), dtype='float32')\n",
    "\n",
    "# output the first row of the input matrix\n",
    "first_row = Lambda(lambda x: x[:,0,:])(inputs)\n",
    "\n",
    "# output the first column of the input matrix\n",
    "first_column = Lambda(lambda x: x[:,:,0])(inputs)\n",
    "\n",
    "# output all values multiplied by 2\n",
    "mul_2 = Lambda(lambda x: x*2.0)(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[first_row, first_column, mul_2])\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "x = np.array([\n",
    "    [[1,1,1,1],\n",
    "     [2,2,2,2],\n",
    "     [3,3,3,3],\n",
    "     [4,4,4,4]]\n",
    "], dtype=np.float32)\n",
    "\n",
    "x,y,z = model.predict(x)\n",
    "print('First row:')\n",
    "print(x)\n",
    "print('\\nFirst column:')\n",
    "print(y)\n",
    "print('\\nMultiplied by 2:')\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge layer\n",
    "\n",
    "[Merge layers](https://keras.io/layers/merge/) take as input a list of tensors (all of the same shape), aggregate them by some operation and return a single tensor (also of the same shape).\n",
    "\n",
    "Merge operations are:\n",
    " * concatenate\n",
    " * average\n",
    " * sum\n",
    " * min/max\n",
    " * etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated rows:\n",
      "[[1. 1. 1. 1. 2. 2. 2. 2. 3. 3. 3. 3. 4. 4. 4. 4.]]\n",
      "\n",
      "Averaged rows:\n",
      "[[2.5 2.5 2.5 2.5]]\n",
      "\n",
      "Summed rows:\n",
      "[[10. 10. 10. 10.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Concatenate, Lambda, Average, Dense, Add\n",
    "from keras.models import Model\n",
    "\n",
    "# define the input shape\n",
    "inputs = Input(shape=(4,4), dtype='float32')\n",
    "\n",
    "# slice by row\n",
    "word_vector_rows = [Lambda(lambda x: x[:,i,:])(inputs) for i in range(4)]\n",
    "\n",
    "# concatenate rows\n",
    "concat_out = Concatenate()(word_vector_rows)\n",
    "\n",
    "# average rows\n",
    "avg_out = Average()(word_vector_rows)\n",
    "\n",
    "# add rows\n",
    "sum_out = Add()(word_vector_rows)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[concat_out, avg_out, sum_out])\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "x = np.array([\n",
    "    [\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3],\n",
    "    [4,4,4,4],        \n",
    "    ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "concat_out_val, avg_out_val, sum_out_val = model.predict(x)\n",
    "\n",
    "print('Concatenated rows:')\n",
    "print(concat_out_val)\n",
    "print('\\nAveraged rows:')\n",
    "print(avg_out_val)\n",
    "print('\\nSummed rows:')\n",
    "print(sum_out_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This is basicly a **reduce** operation, but this is not available in Keras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
