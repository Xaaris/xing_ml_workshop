{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ML workflow\n",
    "\n",
    "Unless you do a [Kaggle](https://www.kaggle.com/) challenge or work in a research project model training is usually only a small part of a machine learning project.\n",
    "\n",
    "The workflow usually consists of the following steps:\n",
    "\n",
    " * Collect data\n",
    "   * How easy is it got collect the data?\n",
    "   * Labelling problem for supervised learning\n",
    "   * Join datasets from different sources\n",
    "   * Privacy and legal issues\n",
    " * Preprocess data\n",
    "   * Cleaning data\n",
    "   * Normalization\n",
    "   * Tokenization for text input\n",
    "   * Augmentation for image input\n",
    " * Train model\n",
    "   * Framework selection\n",
    "   * Model architecture\n",
    "   * Cloud vs. own hardware\n",
    "   * Local vs. distributed training\n",
    "   * Scaling\n",
    "   * Memory issues\n",
    " * Evaluate model\n",
    "   * Hyperparameter selection\n",
    " * Deploy model\n",
    "   * Online deployment (e.g. RPC service)\n",
    "   * Offline deployment (e.g. as Spark, Flink or batch job)\n",
    "   * Library deployment (e.g. model + code bundle that can be used by other teams)\n",
    " * Make predictions\n",
    "   * Monitor preditions\n",
    "   * Compare predictions with observed outcome\n",
    " * Improve model\n",
    "   * Here it starts all over again\n",
    "\n",
    "You see that most tasks require software engineering or data engineering skills.\n",
    "\n",
    "\n",
    "## Principles\n",
    "\n",
    "Productivity:\n",
    " * Enable developers to use ML: standardize algorithms, dataset and workflows\n",
    " * Training a model should be easy for engineers of varying ML experience\n",
    " * Standard ML algorithm should be implemented only once in a reusable manner\n",
    " * Rerun pipelines with different inputs and parameters\n",
    " * Run multiple experiments at the same time, distributed training, GPU \n",
    "\n",
    "Reproducability:\n",
    " * Record train parameters and inputs, store model, record performance\n",
    " * Everybody should be able to easily search past experiments, view results, share with others, and start new variants of a given experiment.\n",
    " \n",
    "Model deployment \n",
    " * Standardize model deployment: avoid engineering teams have to create a custom serving container specific to the project\n",
    " * Support for offline and near-realtime features\n",
    "\n",
    "Deploy multiple model versions at the same time\n",
    " * transition between model versions\n",
    " * A/B testing\n",
    "\n",
    "\n",
    "Monitor deployed models\n",
    " * Monitor model performance\n",
    " * Detect slowly shifting distributions in the underlying data\n",
    " * Log a percentage of the predictons and later compare them to the observed outcome\n",
    "\n",
    "\n",
    "Monitor model training\n",
    " * Plot loss, accuracy etc.\n",
    " * Plot computational graph\n",
    " * Mean and variance of activations over time\n",
    " * Mean and variance of gradients over time\n",
    " * Mean and variance of parameter updates over time\n",
    "\n",
    "## Model deployment\n",
    "\n",
    "Deployment types:\n",
    "\n",
    " * Offline deployment. The model is deployed to an offline container and run in a Spark job to generate batch predictions either on demand or on a repeating schedule.\n",
    " * Online deployment. The model is deployed to an online prediction service cluster (generally containing hundreds of machines behind a load balancer) where clients can send individual or batched prediction requests as network RPC calls.\n",
    " * Library deployment. We intend to launch a model that is deployed to a serving container that is embedded as a library in another service and invoked via a Java API.\n",
    "\n",
    "\n",
    "## Training metadata:\n",
    "\n",
    " * Who trained the model\n",
    " * Start and end time of the training job\n",
    " * Full model configuration (features used, hyper-parameter values, etc.)\n",
    " * Reference to training and test data sets\n",
    " * Distribution and relative importance of each feature\n",
    " * Model accuracy metrics\n",
    " * Standard charts and graphs for each model type (e.g. ROC curve, PR curve, and confusion matrix for a binary classifier)\n",
    " * Full learned parameters of the model\n",
    " * Summary statistics for model visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
