{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build reliable, uniform, and reproducible pipelines for creating and managing training and prediction data at scale. \n",
    "\n",
    "Productivity, run multiple experiments at the same time, distributed training, GPU\n",
    "\n",
    "Enable developers to use ML: standardize algorithms, dataset and workflows, UI\n",
    "\n",
    "Reproducability: record train parameters and inputs, store model, record performance\n",
    "\n",
    "Monitor training and application of ML models\n",
    "\n",
    "Standardize model deployment\n",
    "\n",
    "engineering team had to create a custom serving container specific to the project at hand.\n",
    "\n",
    "end-to-end system\n",
    "\n",
    "ML anti-patterns:\n",
    " * Machine Learning: The High-Interest Credit Card of Technical Debt\n",
    " * https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf\n",
    " \n",
    " \n",
    "Workflow:\n",
    " * Manage data\n",
    " * Train models\n",
    " * Evaluate models\n",
    " * Deploy models\n",
    " * Make predictions\n",
    " * Monitor predictions \n",
    " \n",
    "Support for offline and near-realtime features\n",
    "\n",
    "Model repository\n",
    "\n",
    "Training metadata:\n",
    " * Who trained the model\n",
    " * Start and end time of the training job\n",
    " * Full model configuration (features used, hyper-parameter values, etc.)\n",
    " * Reference to training and test data sets\n",
    " * Distribution and relative importance of each feature\n",
    " * Model accuracy metrics\n",
    " * Standard charts and graphs for each model type (e.g. ROC curve, PR curve, and confusion matrix for a binary classifier)\n",
    " * Full learned parameters of the model\n",
    " * Summary statistics for model visualization\n",
    " \n",
    "Model deployment types:\n",
    "\n",
    " * Offline deployment. The model is deployed to an offline container and run in a Spark job to generate batch predictions either on demand or on a repeating schedule.\n",
    " * Online deployment. The model is deployed to an online prediction service cluster (generally containing hundreds of machines behind a load balancer) where clients can send individual or batched prediction requests as network RPC calls.\n",
    " * Library deployment. We intend to launch a model that is deployed to a serving container that is embedded as a library in another service and invoked via a Java API. (It is not shown in Figure 8, below, but works similarly to online deployment).\n",
    "\n",
    "\n",
    "Deploy multiple model versions at the same time:\n",
    " * transition from old to new model\n",
    " * a/b tests\n",
    " \n",
    "Automatically log a percentage of the predictions that it makes and then later join those predictions to the observed outcomes (or labels) generated by the data pipeline. \n",
    "\n",
    "Model visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
